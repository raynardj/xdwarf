<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-archivearticle1.dtd?><?SourceDTD.Version 1.1?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">25420014</article-id><article-id pub-id-type="publisher-id">PONE-D-14-09001</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0111924</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and Life Sciences</subject><subj-group><subject>Ecology</subject><subj-group><subject>Ecosystems</subject><subj-group><subject>Forests</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Computer and Information Sciences</subject><subj-group><subject>Geoinformatics</subject><subj-group><subject>Remote Sensing Imagery</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Research and Analysis Methods</subject><subj-group><subject>Imaging Techniques</subject></subj-group></subj-group></article-categories><title-group><article-title>Standardizing the Protocol for Hemispherical Photographs: Accuracy Assessment of Binarization Algorithms</article-title><alt-title alt-title-type="running-head">Accuracy of Binarization Algorithms for Hemispherical Photographs</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Glatthorn</surname><given-names>Jonas</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref><xref ref-type="corresp" rid="cor1">
<sup>*</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Becksch&#x000e4;fer</surname><given-names>Philip</given-names></name><xref ref-type="aff" rid="aff2">
<sup>2</sup>
</xref></contrib></contrib-group><aff id="aff1">
<label>1</label>
<addr-line>Department of Plant Ecology, Albrecht von Haller Institute of Plant Sciences, Georg-August-Universit&#x000e4;t G&#x000f6;ttingen, G&#x000f6;ttingen, Germany</addr-line>
</aff><aff id="aff2">
<label>2</label>
<addr-line>Chair of Forest Inventory and Remote Sensing, Georg-August-Universit&#x000e4;t G&#x000f6;ttingen, G&#x000f6;ttingen, Germany</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Rocchini</surname><given-names>Duccio</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">
<addr-line>Fondazione Edmund Mach, Research and Innovation Centre, Italy</addr-line>
</aff><author-notes><corresp id="cor1">* E-mail: <email>jglatth@gwdg.de</email></corresp><fn fn-type="COI-statement"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><fn fn-type="con"><p>Conceived and designed the experiments: JG PB. Performed the experiments: JG PB. Analyzed the data: JG PB. Contributed reagents/materials/analysis tools: JG PB. Wrote the paper: JG PB.</p></fn></author-notes><pub-date pub-type="collection"><year>2014</year></pub-date><pub-date pub-type="epub"><day>24</day><month>11</month><year>2014</year></pub-date><volume>9</volume><issue>11</issue><elocation-id>e111924</elocation-id><history><date date-type="received"><day>4</day><month>3</month><year>2014</year></date><date date-type="accepted"><day>9</day><month>10</month><year>2014</year></date></history><permissions><copyright-statement>&#x000a9; 2014 Glatthorn, Becksch&#x000e4;fer</copyright-statement><copyright-year>2014</copyright-year><copyright-holder>Glatthorn, Becksch&#x000e4;fer</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p></license></permissions><abstract><p>Hemispherical photography is a well-established method to optically assess ecological parameters related to plant canopies; e.g. ground-level light regimes and the distribution of foliage within the crown space. Interpreting hemispherical photographs involves classifying pixels as either sky or vegetation. A wide range of automatic thresholding or binarization algorithms exists to classify the photographs. The variety in methodology hampers ability to compare results across studies. To identify an optimal threshold selection method, this study assessed the accuracy of seven binarization methods implemented in software currently available for the processing of hemispherical photographs. Therefore, binarizations obtained by the algorithms were compared to reference data generated through a manual binarization of a stratified random selection of pixels. This approach was adopted from the accuracy assessment of map classifications known from remote sensing studies. Percentage correct (<inline-formula><inline-graphic xlink:href="pone.0111924.e001.jpg"/></inline-formula>) and kappa-statistics (<inline-formula><inline-graphic xlink:href="pone.0111924.e002.jpg"/></inline-formula>) were calculated. The accuracy of the algorithms was assessed for photographs taken with automatic exposure settings (auto-exposure) and photographs taken with settings which avoid overexposure (histogram-exposure). In addition, gap fraction values derived from hemispherical photographs were compared with estimates derived from the manually classified reference pixels. All tested algorithms were shown to be sensitive to overexposure. Three of the algorithms showed an accuracy which was high enough to be recommended for the processing of histogram-exposed hemispherical photographs: &#x0201c;Minimum&#x0201d; (<inline-formula><inline-graphic xlink:href="pone.0111924.e003.jpg"/></inline-formula> 98.8%; <inline-formula><inline-graphic xlink:href="pone.0111924.e004.jpg"/></inline-formula> 0.952), &#x0201c;Edge Detection&#x0201d; (<inline-formula><inline-graphic xlink:href="pone.0111924.e005.jpg"/></inline-formula> 98.1%; <inline-formula><inline-graphic xlink:href="pone.0111924.e006.jpg"/></inline-formula> 0.950), and &#x0201c;Minimum Histogram&#x0201d; (<inline-formula><inline-graphic xlink:href="pone.0111924.e007.jpg"/></inline-formula> 98.1%; <inline-formula><inline-graphic xlink:href="pone.0111924.e008.jpg"/></inline-formula> 0.947). The Minimum algorithm overestimated gap fraction least of all (11%). The overestimation by the algorithms Edge Detection (63%) and Minimum Histogram (67%) were considerably larger. For the remaining four evaluated algorithms (IsoData, Maximum Entropy, MinError, and Otsu) an incompatibility with photographs containing overexposed pixels was detected. When applied to histogram-exposed photographs, these algorithms overestimated the gap fraction by at least 180%.</p></abstract><funding-group><funding-statement>The authors' thanks are due to the Advisory Group on International Agricultural Research (BEAF) at the German Agency for International Cooperation (GIZ) and the German Ministry for Economic Cooperation (BMZ) for funding the research project MMC (&#x0201c;Making the Mekong Connected&#x0201d;, Project No. 08.7860.3-001.00) within which this study had been carried out. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="19"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>The authors confirm that all data underlying the findings are fully available without restriction. All relevant data and supporting information is available from the Dryad Digital Repository: <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.5061/dryad.s9652">http://doi.org/10.5061/dryad.s9652</ext-link>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>The authors confirm that all data underlying the findings are fully available without restriction. All relevant data and supporting information is available from the Dryad Digital Repository: <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.5061/dryad.s9652">http://doi.org/10.5061/dryad.s9652</ext-link>.</p></notes></front><body><sec id="s1"><title>Introduction</title><p>Hemispherical photography is an important and frequently applied technique to assess light conditions and canopy structure in forests <xref rid="pone.0111924-Hale1" ref-type="bibr">[1]</xref>. Information about available radiation, as derived from hemispherical photographs, e.g. allows for investigating light response of natural regeneration or habitat choice by insects <xref rid="pone.0111924-Wagner1" ref-type="bibr">[2]</xref>. This information can also be used to model tree growth in forest ecosystems, e.g. with the software BWINPro <xref rid="pone.0111924-Schrder1" ref-type="bibr">[3]</xref>. The techniques major drawback is that obtained values are often not comparable among studies due to non-standardized exposure determination procedures applied during the acquisition <xref rid="pone.0111924-Zhang1" ref-type="bibr">[4]</xref>,<xref rid="pone.0111924-Beckschfer1" ref-type="bibr">[5]</xref> and non-standardized binarization methods applied in the processing of hemispherical photographs <xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref>,<xref rid="pone.0111924-Jaruka1" ref-type="bibr">[7]</xref>. The impact of exposure determination methods on hemispherical photographs was e.g. investigated by <xref rid="pone.0111924-Zhang1" ref-type="bibr">[4]</xref>
<xref rid="pone.0111924-Chen1" ref-type="bibr">[8]</xref>
<xref rid="pone.0111924-Wagner2" ref-type="bibr">[9]</xref> and <xref rid="pone.0111924-Beckschfer1" ref-type="bibr">[5]</xref>. For dark canopy conditions <xref rid="pone.0111924-Beckschfer1" ref-type="bibr">[5]</xref> found that gap fraction values can be up to 900% higher if photographs were auto-exposed and not non-overexposed as recommended by e.g. <xref rid="pone.0111924-Wagner2" ref-type="bibr">[9]</xref>. In the present study we assumed that non-overexposed photographs can be binarized with a higher accuracy than auto-exposed photographs. Nevertheless, auto-exposed photographs were included in the study because auto-exposure is still an often applied exposure determination method in hemispherical photography <xref rid="pone.0111924-Beckschfer1" ref-type="bibr">[5]</xref>.</p><p>In processing hemispherical photographs the binarization or so-called &#x0201c;thresholding&#x0201d; which classifies all pixels of a photograph into either two or three categories is commonly the first step:</p><list list-type="bullet"><list-item><p>Most software classify all pixels in a photograph into two categories: sky and vegetation (binarization, <xref rid="pone-0111924-t001" ref-type="table">Table 1</xref>; <xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref>). Therefore, a global threshold is determined and all pixels with a gray value below or equal that threshold are classified as vegetation, remaining pixels are classified as sky. The threshold is either determined subjectively by an operator (interactive thresholding - e.g. GapLightAnalyzer, Forest Renewal BC, <xref rid="pone.0111924-Frazer1" ref-type="bibr">[10]</xref>) or automatically by an algorithm (e.g. Win-SCANOPY, R&#x000e9;gent Instruments, Canada). Some software additionally allow for an independent threshold determination for separate sectors of the photograph (local thresholding - e.g. CAN-EYE, INRA 2010).</p></list-item></list><table-wrap id="pone-0111924-t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0111924.t001</object-id><label>Table 1</label><caption><title>Binarization methods implemented in currently available software for the processing of digital hemispherical photographs.</title></caption><alternatives><graphic id="pone-0111924-t001-1" xlink:href="pone.0111924.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Software</td><td align="left" rowspan="1" colspan="1">Binarization method</td><td align="left" rowspan="1" colspan="1">Level</td><td align="left" rowspan="1" colspan="1">Included in this study</td><td align="left" rowspan="1" colspan="1">Literature related to the binarization</td><td align="left" rowspan="1" colspan="1">Distribution</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">CAN-EYE</td><td align="left" rowspan="1" colspan="1">True color</td><td align="left" rowspan="1" colspan="1">Pixel or sub-pixel</td><td align="left" rowspan="1" colspan="1">No</td><td align="left" rowspan="1" colspan="1">Not described</td><td align="left" rowspan="1" colspan="1">Freeware (INRA 2010)</td></tr><tr><td align="left" rowspan="1" colspan="1">DHP.exe</td><td align="left" rowspan="1" colspan="1">Interactive global or local thresholds</td><td align="left" rowspan="1" colspan="1">Sub-pixel</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">Freeware (Leblanc et al 2005)</td></tr><tr><td align="left" rowspan="1" colspan="1">Gap Light Analyzer (GLA)</td><td align="left" rowspan="1" colspan="1">Interactive threshold</td><td align="left" rowspan="1" colspan="1">Pixel</td><td align="left" rowspan="1" colspan="1">No</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">Freeware (Frazer et al. 1999)</td></tr><tr><td align="left" rowspan="1" colspan="1">Hemisfer</td><td align="left" rowspan="1" colspan="1">Automatic global or local threshold (2 different)</td><td align="left" rowspan="1" colspan="1">Pixel</td><td align="left" rowspan="1" colspan="1">Yes</td><td align="left" rowspan="1" colspan="1">Nobis and Hunziker 2005, Ridler and Calvard 1978</td><td align="left" rowspan="1" colspan="1">Proprietary (Schleppi)</td></tr><tr><td align="left" rowspan="1" colspan="1">Hemiview</td><td align="left" rowspan="1" colspan="1">Interactive global threshold</td><td align="left" rowspan="1" colspan="1">Pixel</td><td align="left" rowspan="1" colspan="1">No</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">Proprietary, Delta-D Devices, Cambridge, UK</td></tr><tr><td align="left" rowspan="1" colspan="1">LIA32</td><td align="left" rowspan="1" colspan="1">Automatic global threshold (3 different)</td><td align="left" rowspan="1" colspan="1">Pixel</td><td align="left" rowspan="1" colspan="1">Yes</td><td align="left" rowspan="1" colspan="1">Otsu 1979, Kittler and Illingworth 1986, Kapur et al. 1985</td><td align="left" rowspan="1" colspan="1">Freeware (Yamamoto 2004)</td></tr><tr><td align="left" rowspan="1" colspan="1">RGB-Fisheye</td><td align="left" rowspan="1" colspan="1">Interactive or automatic global threshold</td><td align="left" rowspan="1" colspan="1">Pixel</td><td align="left" rowspan="1" colspan="1">No</td><td align="left" rowspan="1" colspan="1">Ishida 2004</td><td align="left" rowspan="1" colspan="1">Freeware (Ishida 2005)</td></tr><tr><td align="left" rowspan="1" colspan="1">SideLook (binary-zation only)</td><td align="left" rowspan="1" colspan="1">Automatic global threshold</td><td align="left" rowspan="1" colspan="1">Pixel</td><td align="left" rowspan="1" colspan="1">Yes</td><td align="left" rowspan="1" colspan="1">Nobis and Hunziker 2005</td><td align="left" rowspan="1" colspan="1">Proprietary (Nobis2005)</td></tr><tr><td align="left" rowspan="1" colspan="1">Winphot</td><td align="left" rowspan="1" colspan="1">Interactive global threshold</td><td align="left" rowspan="1" colspan="1">Pixel</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">Freeware (ter Steege)</td></tr><tr><td align="left" rowspan="1" colspan="1">Win-SCANOPY</td><td align="left" rowspan="1" colspan="1">Classification based on true color; automatic global threshold</td><td align="left" rowspan="1" colspan="1">Pixel</td><td align="left" rowspan="1" colspan="1">No</td><td align="left" rowspan="1" colspan="1">Not described</td><td align="left" rowspan="1" colspan="1">Proprietary, R&#x000e9;gent Instruments, Canada</td></tr></tbody></table></alternatives></table-wrap><list list-type="bullet"><list-item><p>Besides the classes vegetation and sky, mixed pixels are also distinguished i.e. pixels covered by both vegetation and sky. For mixed pixels the fractions of their represented solid angle of the hemisphere covered by vegetation is calculated on a sub-pixel level. Variants of this method are e.g. suggested by <xref rid="pone.0111924-Wagner2" ref-type="bibr">[9]</xref>,<xref rid="pone.0111924-Leblanc1" ref-type="bibr">[11]</xref>,<xref rid="pone.0111924-Schwalbe1" ref-type="bibr">[12]</xref>.</p></list-item></list><p>The multitude of available software products and thresholding algorithms questions the comparability of results obtained by different studies and, in consequence, urges for a standardization of the approach. <xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref>,<xref rid="pone.0111924-Macfarlane1" ref-type="bibr">[13]</xref>, and <xref rid="pone.0111924-Inoue1" ref-type="bibr">[14]</xref> are among others studies dealing with this issue. <xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref> quantified the accuracies of a wide range of automatic global thresholding algorithms. They compared binarized hemispherical photographs against photographs that were interactively binarized by an operator; accuracies were described with the method by <xref rid="pone.0111924-Sezgin1" ref-type="bibr">[15]</xref>. The IsoData algorithm <xref rid="pone.0111924-Ridler1" ref-type="bibr">[16]</xref> was proposed to be the optimal thresholding algorithm for processing hemispherical photographs.</p><p>
<xref rid="pone.0111924-Macfarlane1" ref-type="bibr">[13]</xref> investigated how binarization algorithms impacted on indices derived from hemispherical photographs, e.g. leaf area index (LAI) and canopy openness. <xref rid="pone.0111924-Macfarlane1" ref-type="bibr">[13]</xref> found significant differences but concluded that they were not substantial and had little impact on the results.</p><p>
<xref rid="pone.0111924-Inoue1" ref-type="bibr">[14]</xref> analyzed the thresholding algorithms Maximum Entropy <xref rid="pone.0111924-Kapur1" ref-type="bibr">[17]</xref>, MinError <xref rid="pone.0111924-Kittler1" ref-type="bibr">[18]</xref>, and Otsu's method <xref rid="pone.0111924-Otsu1" ref-type="bibr">[19]</xref> implemented in the software LIA32 <xref rid="pone.0111924-Yamamoto1" ref-type="bibr">[20]</xref>. As a reference, hemispherical photographs were interactively binarized by 21 operators. The median of the manually defined thresholds was assumed to be optimal and was used for the evaluation of the thresholding algorithms. The algorithm Maximum Entropy was found to be biased towards lower threshold values and larger gap fractions. Otsu's method was proposed to be the best algorithm for photographs with a low gap fractions (&#x0003c;10%), MinError was judged to be appropriate for photographs with higher gap fractions.</p><p>
<xref rid="pone.0111924-Cescatti1" ref-type="bibr">[21]</xref> introduced the linear ratio method which circumvents the binarization of hemispherical photographs to estimate canopy gap fraction. It requires that photographs taken beneath the canopy are related to photographs taken simultaneously above the canopy or on close-by open land locations. Using plant area and clumping index values estimated with the LAI 2000 Plant Canopy Analyzer (LI-COR, Lincoln, Nebraska, USA) as a reference, <xref rid="pone.0111924-Cescatti1" ref-type="bibr">[21]</xref> compared the results of the linear ratio method with those obtained from photographs which were either thresholded interactively or by the algorithms IsoData <xref rid="pone.0111924-Ridler1" ref-type="bibr">[16]</xref> or Edge Detection <xref rid="pone.0111924-Nobis1" ref-type="bibr">[22]</xref>. <xref rid="pone.0111924-Cescatti1" ref-type="bibr">[21]</xref> concluded that the linear ratio method was of higher accuracy than the other techniques. But as the linear ratio method requires taking reference photographs it is more time consuming.</p><p>In the assessment of accuracies, subjectivity becomes an important issue as soon as a human operator is involved in the classification process <xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref>,<xref rid="pone.0111924-Englund1" ref-type="bibr">[23]</xref>. To circumvent subjectivity, several studies assessed the accuracy of binarization algorithms by comparing specific parameters derived from hemispherical photographs (e.g. LAI) to values acquired with &#x0201d;non-photographic&#x0201d; methods (e.g. LAI-2000; LI-COR, Lincoln, Nebraska, USA) <xref rid="pone.0111924-Macfarlane1" ref-type="bibr">[13]</xref>,<xref rid="pone.0111924-Cescatti1" ref-type="bibr">[21]</xref>,<xref rid="pone.0111924-Nobis1" ref-type="bibr">[22]</xref>,<xref rid="pone.0111924-Ishida1" ref-type="bibr">[24]</xref>,<xref rid="pone.0111924-Kato1" ref-type="bibr">[25]</xref>. This approach allows for the exclusion of subjective steps during the evaluation process, but has drawbacks: (1) results are influenced by possible mistakes made by the devices used as a reference, see <xref rid="pone.0111924-Ryu1" ref-type="bibr">[26]</xref> for the LAI-2000, (2) classification errors which compensate for each other cannot be detected, and (3) there is no consensus in the scientific community on how to derive LAI values from hemispherical photographs <xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref>. Another approach to evaluate classification algorithms is to compare automatically thresholded photographs against those interactively thresholded by human operators (e.g. <xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref>,<xref rid="pone.0111924-Inoue1" ref-type="bibr">[14]</xref>); also this approach suffers from subjectivity. A comparison of 10 photographs, thresholded by 10 different operators was done by <xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref> to assess the operators' impact on gap fraction values. They concluded that the operator dependent thresholding provides a disturbing factor that interferes with reproducibility, and hampers a reliable comparison of sites and studies.</p><p>To reduce subjectivity, for the acquisition of reference data we applied an approach frequently used in the accuracy assessment of remote sensing products <xref rid="pone.0111924-Congalton1" ref-type="bibr">[27]</xref> and studies on character recognition <xref rid="pone.0111924-BarneySmith1" ref-type="bibr">[28]</xref>. Within each photograph single pixels were selected and assigned to the classes sky or vegetation by the author. On a pixel basis this discrimination can be made very accurately, especially if compared to setting a global threshold which requires the operator to pay attention to all parts of the photograph simultaneously. Nevertheless, a human operator is involved, and therefore, also this approach is to a certain degree inherently subjective <xref rid="pone.0111924-BarneySmith1" ref-type="bibr">[28]</xref>. However, it is a widely applied method to assess the accuracy of binarization algorithms for document images <xref rid="pone.0111924-Ntirogiannis1" ref-type="bibr">[29]</xref> and it is assumed to provide satisfactory results for hemispherical photographs as well.</p><p>Seven binarization algorithms implemented in publicly available software or recommended for the processing of hemispherical photographs in the literature were evaluated (<xref rid="pone-0111924-t001" ref-type="table">Table 1</xref>). Based on objective measures of binarization accuracy, algorithms which ensure the best possible output were identified.</p></sec><sec sec-type="methods" id="s2"><title>Methods</title><sec id="s2a"><title>Acquisition of hemispherical photographs</title><p>Two hemispherical photographs with different exposure settings were taken at ten locations along a gradient of canopy closure in Xishuangbanna Tropical Botanical Garden, Yunnan, China (UTM/WGS 84: 47N 732940 E, 2426540 N). No specific permissions were required for field studies and no endangered or protected species were involved. All photographs and data is available from the Dryad Digital Repository: <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.5061/dryad.s9652">http://doi.org/10.5061/dryad.s9652</ext-link>.</p><p>A Nikon D70s DSLR camera equipped with a Sigma Circular Fisheye 4.5 mm 1&#x02236;2.8 lens with a field of view of 180&#x000b0; was used. The camera was mounted on a tripod at 1.2 m height to characterize the canopy without the interfering presence of understory vegetation <xref rid="pone.0111924-GonzlezTagle1" ref-type="bibr">[30]</xref>. The camera was leveled to face exactly the vertical using a bubble-level. The top of the camera (position of the flash socket) was orientated to magnetic north using a compass <xref rid="pone.0111924-Beaudet1" ref-type="bibr">[31]</xref>. Photographs were taken without direct sunlight entering the lens <xref rid="pone.0111924-Rich1" ref-type="bibr">[32]</xref> in the early morning, late afternoon, or on overcast days as suggested by <xref rid="pone.0111924-Weiss1" ref-type="bibr">[33]</xref>.</p><p>At each location, one photograph was taken with the camera settings mode &#x0201c;P&#x0201d; (Programmed Auto), ISO &#x0200a;=&#x0200a;400, and matrix metering. By using the exposure compensation function of the camera (+-EV), photographic exposure was determined following the histogram-exposure protocol <xref rid="pone.0111924-Beckschfer1" ref-type="bibr">[5]</xref> which exposes the photograph to the brightest spot within the scene, i.e. the sky, and thus, prevents overexposure. A second photograph was taken at each location using the auto-exposure mode of the camera.</p><p>Visual inspection of the photographs revealed that the vegetation in locations VIII and IX was, in contrast to that in the other photographs, not foliated, and therefore, mainly composed of fine structures i.e. small branches and twigs (<xref ref-type="fig" rid="pone-0111924-g001">Figure 1</xref>). These fine structures resulted in a large amount of mixed pixels. Since mixed pixels are influenced by sky and vegetation likewise, it is difficult to determine to which class they eventually belong to. The results of these photographs were presented but excluded from the statistical analyses.</p><fig id="pone-0111924-g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0111924.g001</object-id><label>Figure 1</label><caption><title>Hemispherical photographs with high and low amounts of mixed pixels.</title><p>Histogram-exposed photographs of site V (A) with foliated vegetation and a low amount of mixed pixels and site VIII (B) with defoliated vegetation and a high amount of mixed pixels.</p></caption><graphic xlink:href="pone.0111924.g001"/></fig></sec><sec id="s2b"><title>The binarization algorithms</title><p>The photographs were classified into sky and vegetation through the application of the algorithms to the photographs' blue color planes. This was expected to provide the best results because of a high contrast between vegetation and sky resulting from low scattering of blue light by leaves <xref rid="pone.0111924-Cescatti1" ref-type="bibr">[21]</xref>. All algorithms determined a global threshold for binarization. As some software (WinSCANOPY, CAN-EYE; <xref rid="pone-0111924-t001" ref-type="table">Table 1</xref>) only store binarized photographs internally but do not offer the option to export them, we were not able to include the binarization methods of these software in the analyses. <xref ref-type="sec" rid="s2">Methods</xref> which classify pixels in more than two categories (e.g. <xref rid="pone.0111924-Schwalbe1" ref-type="bibr">[12]</xref>) or circumvent pixel classification <xref rid="pone.0111924-Cescatti1" ref-type="bibr">[21]</xref> were not included either.</p><p>The following seven algorithms were evaluated in this study; if not stated otherwise the algorithms are implemented in the Auto Threshold Plugin in ImageJ <xref rid="pone.0111924-Rasband1" ref-type="bibr">[34]</xref>:</p><list list-type="bullet"><list-item><p>
<bold>Edge Detection</bold>
<xref rid="pone.0111924-Nobis1" ref-type="bibr">[22]</xref> implemented in SideLook <xref rid="pone.0111924-Nobis2" ref-type="bibr">[35]</xref>: For each possible threshold the contrast of neighboring pixels classified as vegetation and sky is quantified (Edge Value). The threshold with the maximal Edge Value is used for the binarization.</p></list-item><list-item><p>
<bold>IsoData</bold>
<xref rid="pone.0111924-Ridler1" ref-type="bibr">[16]</xref>: The class mean levels of the probability distributions of both classes (vegetation and sky) are iteratively calculated for increasing thresholds. The first threshold which separates the difference of the class mean levels of both distributions in two equally large sections is applied to the photograph.</p></list-item><list-item><p>
<bold>Maximum Entropy</bold>
<xref rid="pone.0111924-Inoue1" ref-type="bibr">[14]</xref> in <xref rid="pone.0111924-Kapur1" ref-type="bibr">[17]</xref>: The gray value histogram is divided by a possible threshold in two separate probability distributions for vegetation and sky pixels. Subsequent, for each of the distributions the entropies are calculated. The threshold which maximizes the sum of the entropies is chosen.</p></list-item><list-item><p>
<bold>MinError</bold>
<xref rid="pone.0111924-Kittler1" ref-type="bibr">[18]</xref>: It is assumed that the threshold divides the gray value histogram in two normally distributed populations. With the Bayes formula an average classification error for each possible threshold, dependent on the class mean levels and the class variances, is calculated. The threshold with the minimum error is used for the classification.</p></list-item><list-item><p>
<bold>Minimum</bold>
<xref rid="pone.0111924-Prewitt1" ref-type="bibr">[36]</xref>: The gray value histogram is iteratively smoothed through repeated application of a moving average over three neighboring gray values. As soon as a single minimum between two modes is reached in a histogram, the minimum bin of this histogram is used as threshold.</p></list-item><list-item><p>
<bold>Minimum Histogram</bold>
<xref rid="pone.0111924-Beckschfer1" ref-type="bibr">[5]</xref>: This method iteratively calculates new gray value histograms with increasing bin widths. The gray value of the left border of the first bin is always zero. As soon as exactly one minimum between two modes exists in a histogram, the optimal threshold is defined as the middle of this minimum bin of the histogram. An in-house developed R-script is used for its calculation.</p></list-item><list-item><p>
<bold>Otsu</bold>
<xref rid="pone.0111924-Otsu1" ref-type="bibr">[19]</xref>: For both classes (vegetation and sky) the probabilities of class occurrence and class mean levels are calculated for each possible threshold. The threshold with the maximum between-class variance is used.</p></list-item></list></sec><sec id="s2c"><title>Accuracy assessment of the binarization algorithms</title><p>The accuracies of the binarization algorithms were quantified using percentage correct <xref rid="pone.0111924-Congalton1" ref-type="bibr">[27]</xref> and the kappa-statistic (originally suggested by <xref rid="pone.0111924-Cohen1" ref-type="bibr">[37]</xref>). Both statistics are standard measures in remote sensing studies to assess the accuracies of image classifications. To calculate the two statistics a reference, usually generated based on expert opinion and considered true is required <xref rid="pone.0111924-BarneySmith1" ref-type="bibr">[28]</xref>
<xref rid="pone.0111924-Comber1" ref-type="bibr">[38]</xref>. In this study, reference data were obtained through the manual binarization of <italic>n</italic>&#x0200a;=&#x0200a;384 pixels sampled from each photograph. To ensure that reference pixels were distributed across the whole range of possible gray values, each photograph was stratified into <italic>h</italic>&#x0200a;=&#x0200a;16 strata, covering a range of 16 gray values respectively. The sample size per stratum was <inline-formula><inline-graphic xlink:href="pone.0111924.e009.jpg"/></inline-formula> &#x0200a;=&#x0200a;24 pixels. Selected pixels were classified manually into vegetation and sky on single pixel basis. For this purpose the sections of the photographs surrounding a reference pixel were magnified and examined (<xref ref-type="fig" rid="pone-0111924-g002">Figure 2</xref>). Since the gray value of a pixel within a hemispherical photograph is not only influenced by its origin (sky or vegetation) the following additional aspects were taken into account to classify the pixels:</p><fig id="pone-0111924-g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0111924.g002</object-id><label>Figure 2</label><caption><title>Examples of reference pixels.</title><p>(A) Pixel with a low gray value in a dark region of the sky; (B) blooming effect (overexposed vegetation pixel); (C) reflection at vegetation.</p></caption><graphic xlink:href="pone.0111924.g002"/></fig><list list-type="bullet"><list-item><p>
<bold>Position of a pixel within the photograph</bold>: The illumination changes across the different sections of a photograph (<xref ref-type="fig" rid="pone-0111924-g002">Figure 2 A</xref>); therefore, pixels close to the zenith are brighter than pixels close to the horizon <xref rid="pone.0111924-Wagner3" ref-type="bibr">[39]</xref>.</p></list-item><list-item><p>
<bold>Blooming effect</bold>: Saturated sky pixels influence the gray value of neighboring vegetation pixels (<xref ref-type="fig" rid="pone-0111924-g002">Figure 2 B</xref>) <xref rid="pone.0111924-Leblanc1" ref-type="bibr">[11]</xref>.</p></list-item><list-item><p>
<bold>Reflection at vegetation</bold>: The angle of incidence of sunlight to a surface or a light color of a leaf may lead to a higher gray value than is the case for the rest of the vegetation (<xref ref-type="fig" rid="pone-0111924-g002">Figure 2 C</xref>).</p></list-item></list></sec><sec id="s2d"><title>Accuracy assessment of the classification algorithms</title><sec id="s2d1"><title>Confusion matrix</title><p>A confusion matrix is a contingency table which displays how two classifications comply with each other <xref rid="pone.0111924-Congalton1" ref-type="bibr">[27]</xref>. In our case the matrix showed the numbers of reference pixels per stratum <italic>h</italic> and stated how many of them were classified correctly or not by the binarization algorithm (<xref ref-type="fig" rid="pone-0111924-g003">Figure 3</xref>). From this matrix the accuracy measures percentage correct and kappa were estimated.</p><fig id="pone-0111924-g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0111924.g003</object-id><label>Figure 3</label><caption><title>Confusion matrix.</title><p>The matrix is calculated for the <inline-formula><inline-graphic xlink:href="pone.0111924.e010.jpg"/></inline-formula> &#x0200a;=&#x0200a;24 reference pixels of each of <inline-formula><inline-graphic xlink:href="pone.0111924.e011.jpg"/></inline-formula> &#x0200a;=&#x0200a;16 gray value-strata of a hemispherical photograph. Column and row sums show how many pixels were classified by a binarization algorithm (image classified data) and by an operator (reference data) into the categories vegetation (V) and sky (S). The four central cells show how many pixels were classified by an algorithm and the operator in agreement (<inline-formula><inline-graphic xlink:href="pone.0111924.e012.jpg"/></inline-formula>, <inline-formula><inline-graphic xlink:href="pone.0111924.e013.jpg"/></inline-formula>) and in disagreement (<inline-formula><inline-graphic xlink:href="pone.0111924.e014.jpg"/></inline-formula>, <inline-formula><inline-graphic xlink:href="pone.0111924.e015.jpg"/></inline-formula>). The image marginal proportion displays the overall fraction of pixels classified by the algorithm as vegetation (<inline-formula><inline-graphic xlink:href="pone.0111924.e016.jpg"/></inline-formula>) or sky (<inline-formula><inline-graphic xlink:href="pone.0111924.e017.jpg"/></inline-formula>) within the respective stratum. Adapted from Congalton and Green 2009.</p></caption><graphic xlink:href="pone.0111924.g003"/></fig></sec><sec id="s2d2"><title>Percentage correct</title><p>Percentage correct is defined as the fraction of pixels which was classified correctly <xref rid="pone.0111924-Congalton1" ref-type="bibr">[27]</xref>. We calculated percentage correct for each stratum <inline-formula><inline-graphic xlink:href="pone.0111924.e018.jpg"/></inline-formula>, then, the overall <inline-formula><inline-graphic xlink:href="pone.0111924.e019.jpg"/></inline-formula> was calculated per photograph by averaging the per strata values weighted by their strata sizes: <disp-formula id="pone.0111924.e020"><graphic xlink:href="pone.0111924.e020.jpg" position="anchor" orientation="portrait"/></disp-formula>with <inline-formula><inline-graphic xlink:href="pone.0111924.e021.jpg"/></inline-formula> being the number of pixels of stratum <italic>h</italic> and <italic>N</italic> being the total number of pixels in the photograph. The percentage correct and its variance for the single strata were estimated using the equation:<disp-formula id="pone.0111924.e022"><graphic xlink:href="pone.0111924.e022.jpg" position="anchor" orientation="portrait"/></disp-formula>with <inline-formula><inline-graphic xlink:href="pone.0111924.e023.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="pone.0111924.e024.jpg"/></inline-formula> being the probabilities of a randomly selected pixel to be classified correctly as vegetation (VV) or sky (SS). The estimated probabilities were corrected for bias using the image marginal proportions <inline-formula><inline-graphic xlink:href="pone.0111924.e025.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="pone.0111924.e026.jpg"/></inline-formula>:<disp-formula id="pone.0111924.e027"><graphic xlink:href="pone.0111924.e027.jpg" position="anchor" orientation="portrait"/></disp-formula>
</p><p>The notation of the confusion matrix shown in <xref ref-type="fig" rid="pone-0111924-g003">Figure 3</xref> was used.</p></sec><sec id="s2d3"><title>Kappa</title><p>The kappa-statistic <xref rid="pone.0111924-Congalton1" ref-type="bibr">[27]</xref> compares the agreement of an algorithm's classification and the reference<disp-formula id="pone.0111924.e028"><graphic xlink:href="pone.0111924.e028.jpg" position="anchor" orientation="portrait"/></disp-formula>with the agreement of a random classification:</p><p>
<disp-formula id="pone.0111924.e029"><graphic xlink:href="pone.0111924.e029.jpg" position="anchor" orientation="portrait"/></disp-formula>The kappa estimate per stratum was given by</p><p>
<disp-formula id="pone.0111924.e030"><graphic xlink:href="pone.0111924.e030.jpg" position="anchor" orientation="portrait"/></disp-formula>For each photograph the overall kappa was calculated as the weighted average of the per strata kappa estimates:</p><p>
<disp-formula id="pone.0111924.e031"><graphic xlink:href="pone.0111924.e031.jpg" position="anchor" orientation="portrait"/></disp-formula>
</p><p>The calculation of the variance of kappa for the single strata was not formulated here (see <xref rid="pone.0111924-Congalton1" ref-type="bibr">[27]</xref> for details).</p></sec></sec><sec id="s2e"><title>Gap fraction</title><p>The effect of misclassification on subsequent results was demonstrated by means of the gap fraction, which is the basic measure for the calculation of several canopy structure related indices, like LAI <xref rid="pone.0111924-Jonckheere2" ref-type="bibr">[40]</xref> and the direct and indirect site factors <xref rid="pone.0111924-Frazer2" ref-type="bibr">[41]</xref>. Gap fraction <inline-formula><inline-graphic xlink:href="pone.0111924.e032.jpg"/></inline-formula> was defined as the portion of a photograph's pixels classified as sky and was calculated for the whole photograph. No separation into specific regions of the hemisphere, as e.g. in <xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref>,<xref rid="pone.0111924-VanGardingen1" ref-type="bibr">[42]</xref> was done. This variant of gap fraction is sometimes also referred to as canopy openness <xref rid="pone.0111924-Frazer1" ref-type="bibr">[10]</xref> or sky-view factor <xref rid="pone.0111924-Oke1" ref-type="bibr">[43]</xref>.</p><p>Misclassification of pixels does not directly lead to a misestimation of gap fraction. If the same amount of misclassified pixels of a hemispherical photograph is classified as sky and vegetation, gap fraction does not change compared to a classification which is perfectly in agreement with the reference. To assess the actual impact of misclassifications, therefore, gap fraction was estimated on the basis of the reference pixels as well:<disp-formula id="pone.0111924.e033"><graphic xlink:href="pone.0111924.e033.jpg" position="anchor" orientation="portrait"/></disp-formula>with <inline-formula><inline-graphic xlink:href="pone.0111924.e034.jpg"/></inline-formula> being the numbers of reference pixels classified as sky by the operator and <inline-formula><inline-graphic xlink:href="pone.0111924.e035.jpg"/></inline-formula> being the sample size in stratum <inline-formula><inline-graphic xlink:href="pone.0111924.e036.jpg"/></inline-formula>. The misestimation of the gap fraction by the algorithms was calculated by dividing <inline-formula><inline-graphic xlink:href="pone.0111924.e037.jpg"/></inline-formula>through <inline-formula><inline-graphic xlink:href="pone.0111924.e038.jpg"/></inline-formula>.</p></sec><sec id="s2f"><title>Data analysis</title><p>The accuracies of the different binarization algorithms were estimated and their implications for gap fraction values as derived from hemispherical photographs were assessed. Analyses of the dependence of percentage correct, kappa, and gap fraction on the algorithms were carried out for differently exposed photographs separately. The residuals of two-way ANOVA models were tested for normal distribution and sphericity (Kolmogorov-Smirnov-test and Mauchly's-sphericity-test). Based on these tests, normal distribution of kappa was accepted but percentage correct and gap fraction were not normally distributed. For transformed values (percentage correct: exponentiation by ten; gap fraction: logarithm to the basis of ten) the normal distribution was accepted. All following statistical analyses were done with the transformed values.</p><p>Sphericity had to be declined for all statistical models; therefore, the very robust Bonferroni procedure was applied <xref rid="pone.0111924-Park1" ref-type="bibr">[44]</xref>. Accordingly, for all multiple comparisons of the effects of the algorithms and the exposure settings t-tests with Bonferroni-adjusted p-values were used. All statistical tests were done with a significance level of 0.95 and throughout the paper the error of parameter estimates was reported with a 95% confidence interval. All statistical processing was done in R 2.15.3 <xref rid="pone.0111924-R1" ref-type="bibr">[45]</xref>.</p></sec></sec><sec id="s3"><title>Results</title><sec id="s3a"><title>Quantitative evaluation of the classification algorithms</title><p>Due to large amounts of mixed pixels the estimated accuracies of photographs VIII and IX differed greatly from those of the other photographs (<xref ref-type="fig" rid="pone-0111924-g004">Figure 4</xref>). Not considering these two photographs, the algorithms can be clustered by their binarization accuracies into three groups. The algorithms that ranked highest according to percentage correct and kappa were Minimum, Minimum-Histogram, and Edge Detection. All three algorithms achieved constantly high binarization accuracies for both exposure settings. The second group consisting of the algorithms IsoData, Otsu, and Maximum-Entropy had lower estimated accuracies and higher variances than those of the first group. Their estimated accuracies were higher with histogram-exposed photographs than with auto-exposed photographs. The differences of the mean accuracies of the algorithms of the first group to those of the second group were significant for all auto-exposed photographs (p-value &#x0003c;0.00074). For the histogram-exposed photographs most differences were significant as well. The last group consisted of the MinError algorithm only. Its accuracy was higher with auto-exposed photographs than with histogram-exposed ones; its accuracy estimates showed a high variation with some values being similar to those of the first group but very low values for some photographs as well.</p><fig id="pone-0111924-g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0111924.g004</object-id><label>Figure 4</label><caption><title>Accuracy assessment of seven binarization algorithms for hemispherical photographs</title><p>. Percentage correct and kappa values of binarizations obtained from different algorithms applied to hemispherical photographs. Photographs were taken at ten locations (indicated by latin numbers) and either histogram- or auto-exposed. Whiskers represent confidence intervals with a confidence level of 95%.</p></caption><graphic xlink:href="pone.0111924.g004"/></fig><p>The Minimum algorithm achieved independent of the exposure settings (auto-exposure: AE and histogram-exposure: HE) the highest percentage correct estimate for all analyzed photographs (AE: 98.1%&#x000b1;0.8%, HE: 98.8%&#x000b1;1.4%, <xref ref-type="fig" rid="pone-0111924-g004">Figure 4 A and B</xref>). The difference between the percentage correct estimates of the Minimum algorithm and the second and third ranked algorithms Minimum Histogram (AE: 97.9%&#x000b1;0.9%, HE: 98.1%&#x000b1;1.5%) and Edge Detection (AE: 97.1%&#x000b1;1.1%, HE: 98.1%&#x000b1;2.3%) were small (&#x0003c;0.97%).</p><p>The estimated kappa values of the three algorithms showed similar patterns as the percentage correct values. Except for photograph no. I, the algorithms Minimum (AE: 0.881&#x000b1;0.123, HE: 0,952&#x000b1;0.034), Minimum-Histogram (AE: 0.878&#x000b1;0.126, HE: 0,947&#x000b1;0.038), and Edge Detection (AE: 0.883&#x000b1;0.126, HE: 0,950&#x000b1;0.035) were ranked highest with minor, non-significant differences between one another (<xref ref-type="fig" rid="pone-0111924-g004">Figure 4 C and D</xref>) for both exposure settings (AE and HE). The kappa values of the classifications of auto-exposed photographs had a more than ten times higher variance than those of histogram-exposed photographs.</p><p>The algorithms Otsu and IsoData produced almost identical results. The threshold values of both were either the same or one gray value apart from each other. The percentage correct estimates of their classifications were 90.4%&#x000b1;0.03% (AE) and 94.9%&#x000b1;5.91% (HE). The kappa estimates were 0.812&#x000b1;0.111 (AE) and 0.916&#x000b1;0.083 (HE). Differences between the exposure settings were significant in both cases (p-value &#x0003c;0.0016). The Maximum Entropy algorithm achieved lower percentage correct (AE: 82.0%&#x000b1;5.8%, HE: 94.1%&#x000b1;5.4%) and kappa (AE: 0.715&#x000b1;0.155, HE: 0.906&#x000b1;0.076) estimates than the IsoData algorithm. The classifications of the histogram-exposed photographs of all three algorithms were equally accurate (no significant difference, p-value&#x0003e;0.23). The auto-exposed photographs were classified by Maximum Entropy with a significantly lower percentage correct and kappa than by IsoData and Otsu (p-value &#x0003c;0.0005).</p><p>The MinError algorithm classified the photographs with varying accuracies. The auto-exposed photographs were classified with a percentage correct between 87% and 98% and a kappa between 0.79 and 0.87. The histogram-exposed photographs were classified with a lower accuracy with a percentage correct between 70% and 89% and a kappa between 0.00 and 0.87. The differences of MinError to the other algorithms were significant for the percentage correct estimates of the histogram-exposed photographs (p-value &#x0003c;0.00052). The kappa estimates of all photographs and the percentage correct estimates of the auto-exposed photographs of MinError were not significantly different to the other algorithms.</p></sec><sec id="s3b"><title>Impact of the binarization algorithms on gap fraction values</title><p>Compared to gap fraction estimates based on the reference pixels, the algorithms of the first group overestimated the gap fraction of the auto-exposed photographs on average by 3% (Minimum), 5% (Minimum-Histogram), and 25% (Edge Detection, <xref ref-type="fig" rid="pone-0111924-g005">Figure 5</xref>). Between Minimum and Minimum Histogram there was no significant difference, but the difference of Edge Detection to both algorithms was significant (p-value &#x0003c;0.0000056). The misestimations of the histogram-exposed photographs were with 11%, 63%, and 67% considerably larger. The difference between the Minimum algorithm and both other algorithms of the first group were significant (p-value &#x0003c;0.0052).</p><fig id="pone-0111924-g005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0111924.g005</object-id><label>Figure 5</label><caption><title>Misestimation of gap fraction values by binarization algorithms.</title><p>For each algorithm, misestimation was quantified per photograph by dividing the estimated gap fraction of the algorithm (<inline-formula><inline-graphic xlink:href="pone.0111924.e039.jpg"/></inline-formula>) by the gap fraction estimated from manually classified reference pixels (<inline-formula><inline-graphic xlink:href="pone.0111924.e040.jpg"/></inline-formula>). Misestimations are displayed for histogram- and auto-exposed photographs. The horizontal line indicates the best possible classification.</p></caption><graphic xlink:href="pone.0111924.g005"/></fig><p>All other algorithms overestimated the gap fractions of the auto-exposed photographs by more than 80% and those of the histogram-exposed photographs by more than 180%.</p></sec></sec><sec id="s4"><title>Discussion</title><sec id="s4a"><title>Accuracy of the algorithms</title><p>The algorithms binarized the hemispherical photographs with varying accuracies which in consequence impacted the derived gap fraction estimates. This emphasized the necessity to standardize protocols for the processing of hemispherical photographs.</p><p>In terms of accuracy measures the algorithms were ranked similarly for auto-exposed and histogram-exposed photographs. The algorithms Minimum, Minimum Histogram, and Edge Detection were identified to binarize hemispherical photographs with the highest accuracies. The differences between these three algorithms were not significant and also based on the misestimation of gap fraction by these algorithms, a clear assignment of a first rank was not possible. All three algorithms were identified suitable for the classification of hemispherical photographs into sky and vegetation. The occasionally very low and variable accuracies of the other algorithms (IsoData, Maximum Entropy, Otsu, and MinError) indicated that these algorithms should not be used for the binarization of hemispherical photographs.</p></sec><sec id="s4b"><title>The overexposure issue</title><p>As auto-exposure leads to a loss of information on sky and of vegetation pixels <xref rid="pone.0111924-Zhang1" ref-type="bibr">[4]</xref>,<xref rid="pone.0111924-Chen1" ref-type="bibr">[8]</xref>,<xref rid="pone.0111924-Wagner2" ref-type="bibr">[9]</xref>, no algorithm is likely to work correctly with auto-exposed photographs. Even a human operator would not be able to detect vegetation pixels if they were overexposed, hence, in auto-exposed photographs a manual classification of reference pixels is. Therefore, the accuracy measures of the auto-exposed photographs can hardly be interpreted as being calculated on basis of a &#x0201c;true&#x0201d; reference. They should rather be seen as an index which points out the best possible binarizations under the given circumstances.</p><p>All tested algorithms except Edge Detection are histogram based and use gray value frequencies for the calculation of thresholds. Overexposure, frequently occurring in auto-exposed photographs, influences the shape of the histogram, with overexposed pixels forming a distinct peak at the bright end of the histogram's x-axis (<xref rid="pone.0111924-Beckschfer1" ref-type="bibr">[5]</xref>, <xref ref-type="fig" rid="pone-0111924-g006">Figure 6</xref>). The shape of a photograph's gray value histogram affects the thresholds set by the algorithms IsoData, Maximum Entropy, and Otsu, which separate vegetation and sky pixels into two distributions. With histogram-exposure the highest gray value is assigned to the brightest spot in the scene. This has the effect that on histogram-exposed photographs a lower threshold is set by the algorithms than on auto-exposed photographs (see section 0). Also the visual impression of the binarized photographs and the overestimation of gap fraction by these algorithms (<xref ref-type="fig" rid="pone-0111924-g005">Figure 5 A and B</xref>) indicate that mainly vegetation pixels were misclassified. The estimated binarization accuracies of the histogram-exposed photographs were significantly higher for all three algorithms. Hence, IsoData, Maximum Entropy, and Otsu's method require photographs without overexposed pixels.</p><fig id="pone-0111924-g006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0111924.g006</object-id><label>Figure 6</label><caption><title>Overexposure of sky regions in hemispherical photographs.</title><p>Gray value histograms of the blue color plane of the photographs taken on site VI with auto-exposure (A) and histogram-exposure (B).</p></caption><graphic xlink:href="pone.0111924.g006"/></fig><p>The results obtained by the algorithms Minimum and Minimum Histogram might also be affected by overexposure occurring in photographs. Both algorithms search for a gray value with a particular low frequency, i.e. the minimum. As overexposed pixels form a peak at the bright end of the photograph's gray value histogram, the &#x0201c;true&#x0201d; minimum of a scene, separating sky and vegetation, might be concealed in this peak. Thus, both algorithms would not find a scene's global but a local minimum. As gray value frequencies of sky pixels are approximately normally distributed <xref rid="pone.0111924-Wagner3" ref-type="bibr">[39]</xref> in <xref rid="pone.0111924-Olsson1" ref-type="bibr">[46]</xref>, this might occur if additionally to pure sky pixels vegetation and mixed pixels are overexposed as well. Hence, the algorithms Minimum and Minimum Histogram require hemispherical photographs with no overexposure at all, as e.g. obtained with histogram-exposure, or overexposure limited to sky. With auto-exposed photographs the algorithms Minimum and Minimum-Histogram might not work as intended.</p><p>The Edge Detection algorithm is not histogram based; it searches for a threshold which ensures the highest possible local contrast between classes <xref rid="pone.0111924-Nobis1" ref-type="bibr">[22]</xref>. As the difference between gray values of differently classified, neighboring pixels gets smaller for higher thresholds, a loss of information in very bright parts of photographs has no effect on the threshold determination. Nevertheless, like the algorithms Minimum and Minimum Histogram, Edge Detection requires photographs without overexposure or overexposure limited to gaps, as only in these a scene's &#x0201c;true&#x0201d; threshold is contained.</p><p>Some algorithms can handle overexposure if restricted to sky pixels: Edge detection, Minimum, and Minimum Histogram. For these algorithms it might be beneficial to use a slightly higher exposure than determined by the histogram-exposure method. This would result in a higher contrast between vegetation and sky and potentially allow for a better separability of the classes by algorithms and operators alike. Nevertheless, in the field it is hard to assess whether overexposure affects sky pixels only. A possible solution could be to take several photographs with varying exposures at each location, and later on to assess which exposure ensures the highest contrast between vegetation and sky pixels while avoiding overexposing vegetation pixels by displaying the photographs on a large computer monitor.</p></sec><sec id="s4c"><title>Mixed pixels</title><p>Mixed pixels are covered by vegetation and sky simultaneously; they cannot be binarized unmistakably by an operator or by an algorithm. Present-day hemispherical photography uses high resolution digital cameras. This decreases the ratio of mixed to non-mixed pixels and negative effects are minimized. For correctly exposed hemispherical photographs this error is small enough to be neglected <xref rid="pone.0111924-Macfarlane1" ref-type="bibr">[13]</xref>. Exceptions are photographs like those taken on sites VIII and IX (<xref ref-type="fig" rid="pone-0111924-g001">Figure 1 B</xref>) which contain a large amount of mixed pixels because of their high brightness <xref rid="pone.0111924-Macfarlane1" ref-type="bibr">[13]</xref> and the high amount of visible fine structures. This does not mean binarization results obtained for such sites are necessarily wrong but a reliable accuracy assessment of classifications of such photographs is difficult.</p></sec><sec id="s4d"><title>Comparison with other studies</title><p>
<xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref> proposed the IsoData algorithm as being optimal for the processing of hemispherical photographs. This result was not reproduced by our study. Possible reasons are different exposure settings, another evaluation methodology, and a different way to generate a reference. Also, two of the three best ranking algorithms in our study (Edge Detection and Minimum Histogram) were developed just recently and have not been considered by <xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref> it remains unknown how they would have performed with the methodology of <xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref>.</p><p>
<xref rid="pone.0111924-Macfarlane1" ref-type="bibr">[13]</xref> concluded that differences between classifications of different algorithms are not substantial and have only little impact on indices obtained from hemispherical photographs. Contrasting, our results suggest that considerable differences in binarization accuracy exist between algorithms. One possible reason for this discrepancy could be that <xref rid="pone.0111924-Macfarlane1" ref-type="bibr">[13]</xref> assessed the impact of the algorithms on specific indices, and classification errors which compensate for each other were not accounted for. Another reason for the disagreement of both studies might be the evaluation of different algorithms. None of the algorithms of the present study was addressed and all four algorithms evaluated by <xref rid="pone.0111924-Macfarlane1" ref-type="bibr">[13]</xref> work in a similar way in identifying mixed pixels and allocating them evenly to the classes sky and vegetation.</p><p>The bias of the Maximum Entropy algorithm towards a lower gray value and a larger gap fraction detected by <xref rid="pone.0111924-Inoue1" ref-type="bibr">[14]</xref> was also found in our results. The high accuracies of Otsu's method and MinError <xref rid="pone.0111924-Inoue1" ref-type="bibr">[14]</xref> could not be reproduced by our study. A potential reason for this might be that <xref rid="pone.0111924-Inoue1" ref-type="bibr">[14]</xref> compared binarizations against interactively thresholded photographs which was identified to be highly subjective by several authors (e.g. <xref rid="pone.0111924-Jonckheere1" ref-type="bibr">[6]</xref>,<xref rid="pone.0111924-Inoue1" ref-type="bibr">[14]</xref>,<xref rid="pone.0111924-Cescatti1" ref-type="bibr">[21]</xref>,<xref rid="pone.0111924-Nobis1" ref-type="bibr">[22]</xref>).</p></sec></sec><sec id="s5"><title>Conclusions</title><p>The algorithms Minimum, Edge Detection, and Minimum Histogram achieved the highest binarization accuracies. The latter two algorithms misclassified more vegetation pixels and overestimated gap fraction but differences were not statistically significant. All three algorithms were appropriate for the binarization of hemispherical photographs; at this point no recommendation can be given which of them should be preferred.</p><p>For the algorithms Maximum Entropy, IsoData, and Otsu's method an incompatibility with auto-exposed photographs containing overexposed pixels was detected. Photographs taken with histogram-exposure were binarized with higher accuracies.</p><p>All seven algorithms have been shown to be sensitive to overexposed photographs. Therefore, we strongly recommend applying an exposure determination method which prevents overexposure (e.g. <xref rid="pone.0111924-Beckschfer1" ref-type="bibr">[5]</xref>,<xref rid="pone.0111924-Wagner2" ref-type="bibr">[9]</xref>). Besides the investigated binarization algorithms and exposure settings other factors influence the parameters modeled based on hemispherical photographs. For example, gamma correction of pixel gray values applied by digital cameras <xref rid="pone.0111924-Cescatti1" ref-type="bibr">[21]</xref>, camera type <xref rid="pone.0111924-Inoue2" ref-type="bibr">[47]</xref>, and light and weather conditions on the site <xref rid="pone.0111924-Inoue1" ref-type="bibr">[14]</xref> are known to influence results. Until now, studies only dealt with one or two of these factors at a time. A comprehensive study which addresses the influence of all known factors and possible interrelations would be recommended to standardize the acquisition and processing of hemispherical photograph.</p></sec><sec id="s6"><title>Acknowledgments</title><p>We are grateful to all members of the MMC-project (Making the Mekong Connected) for their support. Especially, we thank Mr. Rhett D. Harrison for facilitating the data collection in Xishuangbanna Tropical Botanical Garden (XTBG). We also wish to thank Mr. Collins Boyobona Kukunda for proof-reading the manuscript.</p></sec></body><back><ref-list><title>References</title><ref id="pone.0111924-Hale1"><label>1</label><mixed-citation publication-type="journal">
<name><surname>Hale</surname><given-names>SE</given-names></name>, <name><surname>Edwards</surname><given-names>C</given-names></name> (<year>2002</year>) <article-title>Comparison of film and digital hemispherical photography across a wide range of canopy densities</article-title>. <source>Agric For Meteorol</source>
<volume>112</volume>:<fpage>51</fpage>&#x02013;<lpage>56</lpage>
<pub-id pub-id-type="doi">10.1016/S0168-1923(02)00042-4</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Wagner1"><label>2</label><mixed-citation publication-type="journal">
<name><surname>Wagner</surname><given-names>S</given-names></name>, <name><surname>K&#x000fc;ssner</surname><given-names>R</given-names></name>, <name><surname>Ammer</surname><given-names>C</given-names></name>, <name><surname>Dohrenbusch</surname><given-names>A</given-names></name> (<year>2004</year>) <article-title>Measurements of radiation and canopy structure in forest stands in the framework of silvicultural studies</article-title>. <source>Forstarchiv</source>
<volume>75</volume>:<fpage>110</fpage>&#x02013;<lpage>121</lpage>.</mixed-citation></ref><ref id="pone.0111924-Schrder1"><label>3</label><mixed-citation publication-type="journal">
<name><surname>Schr&#x000f6;der</surname><given-names>J</given-names></name>, <name><surname>R&#x000f6;hle</surname><given-names>H</given-names></name>, <name><surname>Gerold</surname><given-names>D</given-names></name>, <name><surname>M&#x000fc;nder</surname><given-names>K</given-names></name> (<year>2007</year>) <article-title>Modeling individual-tree growth in stands under forest conversion in East Germany</article-title>. <source>Eur J For Res</source>
<volume>126</volume>:<fpage>459</fpage>&#x02013;<lpage>472</lpage>
<pub-id pub-id-type="doi">10.1007/s10342-006-0167-x</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Zhang1"><label>4</label><mixed-citation publication-type="journal">
<name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Chen</surname><given-names>JM</given-names></name>, <name><surname>Miller</surname><given-names>JR</given-names></name> (<year>2005</year>) <article-title>Determining digital hemispherical photograph exposure for leaf area index estimation</article-title>. <source>Agric For Meteorol</source>
<volume>133</volume>:<fpage>166</fpage>&#x02013;<lpage>181</lpage>
<pub-id pub-id-type="doi">10.1016/j.agrformet.2005.09.009</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Beckschfer1"><label>5</label><mixed-citation publication-type="journal">
<name><surname>Becksch&#x000e4;fer</surname><given-names>P</given-names></name>, <name><surname>Seidel</surname><given-names>D</given-names></name>, <name><surname>Kleinn</surname><given-names>C</given-names></name>, <name><surname>Xu</surname><given-names>J</given-names></name> (<year>2013</year>) <article-title>On the exposure of hemispherical photographs in forests</article-title>. <source>IForest - Biogeosciences For</source>
<volume>6</volume>:<fpage>228</fpage>&#x02013;<lpage>237</lpage>
<pub-id pub-id-type="doi">10.3832/ifor0957-006</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Jonckheere1"><label>6</label><mixed-citation publication-type="journal">
<name><surname>Jonckheere</surname><given-names>I</given-names></name>, <name><surname>Nackaerts</surname><given-names>K</given-names></name>, <name><surname>Muys</surname><given-names>B</given-names></name>, <name><surname>Coppin</surname><given-names>P</given-names></name> (<year>2005</year>) <article-title>Assessment of automatic gap fraction estimation of forests from digital hemispherical photography</article-title>. <source>Agric For Meteorol</source>
<volume>132</volume>:<fpage>96</fpage>&#x02013;<lpage>114</lpage>
<pub-id pub-id-type="doi">10.1016/j.agrformet.2005.06.003</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Jaruka1"><label>7</label><mixed-citation publication-type="journal">
<name><surname>Jar&#x0010d;u&#x00161;ka</surname><given-names>B</given-names></name>, <name><surname>Kucbel</surname><given-names>S</given-names></name>, <name><surname>Jaloviar</surname><given-names>P</given-names></name>. <collab>others</collab> (<year>2010</year>) <article-title>Comparison of output results from two programmes for hemispherical image analysis: Gap Light Analyser and WinScanopy</article-title>. <source>J For Sci</source>
<volume>56</volume>:<fpage>147</fpage>&#x02013;<lpage>153</lpage>.</mixed-citation></ref><ref id="pone.0111924-Chen1"><label>8</label><mixed-citation publication-type="journal">
<name><surname>Chen</surname><given-names>JM</given-names></name>, <name><surname>Black</surname><given-names>TA</given-names></name>, <name><surname>Adams</surname><given-names>RS</given-names></name> (<year>1991</year>) <article-title>Evaluation of hemispherical photography for determining plant area index and geometry of a forest stand</article-title>. <source>Agric For Meteorol</source>
<volume>56</volume>:<fpage>129</fpage>&#x02013;<lpage>143</lpage>
<pub-id pub-id-type="doi">10.1016/0168-1923(91)90108-3</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Wagner2"><label>9</label><mixed-citation publication-type="journal">
<name><surname>Wagner</surname><given-names>S</given-names></name> (<year>1998</year>) <article-title>Calibration of grey values of hemispherical photographs for image analysis</article-title>. <source>Agric For Meteorol</source>
<volume>90</volume>:<fpage>103</fpage>&#x02013;<lpage>117</lpage>.</mixed-citation></ref><ref id="pone.0111924-Frazer1"><label>10</label><mixed-citation publication-type="book">Frazer GW (1999) Gap Light Analyzer (GLA), Version 2.0: Imaging software to extract canopy structure and gap light transmission indices from true-colour fisheye photographs, users manual and program documentation. Millbrook, New York: Simon Fraser University, Burnaby, British Columbia, and the Institute of Ecosystem Studies. 36 p.</mixed-citation></ref><ref id="pone.0111924-Leblanc1"><label>11</label><mixed-citation publication-type="journal">
<name><surname>Leblanc</surname><given-names>SG</given-names></name>, <name><surname>Chen</surname><given-names>JM</given-names></name>, <name><surname>Fernandes</surname><given-names>R</given-names></name>, <name><surname>Deering</surname><given-names>DW</given-names></name>, <name><surname>Conley</surname><given-names>A</given-names></name> (<year>2005</year>) <article-title>Methodology comparison for canopy structure parameters extraction from digital hemispherical photography in boreal forests</article-title>. <source>Agric For Meteorol</source>
<volume>129</volume>:<fpage>187</fpage>&#x02013;<lpage>207</lpage>
<pub-id pub-id-type="doi">10.1016/j.agrformet.2004.09.006</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Schwalbe1"><label>12</label><mixed-citation publication-type="journal">
<name><surname>Schwalbe</surname><given-names>E</given-names></name>, <name><surname>Maas</surname><given-names>H-G</given-names></name>, <name><surname>Kenter</surname><given-names>M</given-names></name>, <name><surname>Wagner</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>Hemispheric image modeling and analysis techniques for solar radiation determination in forest ecosystems</article-title>. <source>Photogramm Eng Remote Sens</source>
<volume>75</volume>:<fpage>375</fpage>&#x02013;<lpage>384</lpage>.</mixed-citation></ref><ref id="pone.0111924-Macfarlane1"><label>13</label><mixed-citation publication-type="journal">
<name><surname>Macfarlane</surname><given-names>C</given-names></name> (<year>2011</year>) <article-title>Classification method of mixed pixels does not affect canopy metrics from digital images of forest overstorey</article-title>. <source>Agric For Meteorol</source>
<volume>151</volume>:<fpage>833</fpage>&#x02013;<lpage>840</lpage>
<pub-id pub-id-type="doi">10.1016/j.agrformet.2011.01.019</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Inoue1"><label>14</label><mixed-citation publication-type="journal">
<name><surname>Inoue</surname><given-names>A</given-names></name>, <name><surname>Yamamoto</surname><given-names>K</given-names></name>, <name><surname>Mizoue</surname><given-names>N</given-names></name> (<year>2011</year>) <article-title>Comparison of automatic and interactive thresholding of hemispherical photography</article-title>. <source>J For Sci</source>
<volume>57</volume>:<fpage>78</fpage>&#x02013;<lpage>87</lpage>.</mixed-citation></ref><ref id="pone.0111924-Sezgin1"><label>15</label><mixed-citation publication-type="journal">
<name><surname>Sezgin</surname><given-names>M</given-names></name>, <name><surname>Sankur</surname><given-names>B</given-names></name> (<year>2004</year>) <article-title>Survey over image thresholding techniques and quantitative performance evaluation</article-title>. <source>J Electron Imaging</source>
<volume>13</volume>:<fpage>146</fpage>
<pub-id pub-id-type="doi">10.1117/1.1631315</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Ridler1"><label>16</label><mixed-citation publication-type="journal">
<name><surname>Ridler</surname><given-names>TW</given-names></name>, <name><surname>Calvard</surname><given-names>S</given-names></name> (<year>1978</year>) <article-title>Picture thresholding using an iterative selection method</article-title>. <source>IEEE Trans Syst Man Cybern</source>
<volume>8</volume>:<fpage>630</fpage>&#x02013;<lpage>632</lpage>.</mixed-citation></ref><ref id="pone.0111924-Kapur1"><label>17</label><mixed-citation publication-type="journal">
<name><surname>Kapur</surname><given-names>JN</given-names></name>, <name><surname>Sahoo</surname><given-names>PK</given-names></name>, <name><surname>Wong</surname><given-names>AKC</given-names></name> (<year>1985</year>) <article-title>A new method for gray-level picture thresholding using the entropy of the histogram</article-title>. <source>Comput Vis Graph Image Process</source>
<volume>29</volume>:<fpage>273</fpage>&#x02013;<lpage>285</lpage>
<pub-id pub-id-type="doi">10.1016/0734-189X(85)90125-2</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Kittler1"><label>18</label><mixed-citation publication-type="journal">
<name><surname>Kittler</surname><given-names>J</given-names></name>, <name><surname>Illingworth</surname><given-names>J</given-names></name> (<year>1986</year>) <article-title>Minimum error thresholding</article-title>. <source>Pattern Recognit</source>
<volume>19</volume>:<fpage>41</fpage>&#x02013;<lpage>47</lpage>.</mixed-citation></ref><ref id="pone.0111924-Otsu1"><label>19</label><mixed-citation publication-type="journal">
<name><surname>Otsu</surname><given-names>N</given-names></name> (<year>1979</year>) <article-title>A threshold selection method from gray-level histograms</article-title>. <source>IEEE Trans Syst Man Cybern SMC</source>
<volume>9</volume>:<fpage>62</fpage>&#x02013;<lpage>66</lpage>.</mixed-citation></ref><ref id="pone.0111924-Yamamoto1"><label>20</label><mixed-citation publication-type="other">Yamamoto K (2004) LIA for Win32 (LIA32) - digital hemispherical image processing software. Available: <ext-link ext-link-type="uri" xlink:href="http://www.agr.nagoya-u.ac.jp/~shinkan/LIA32/index-e.html">http://www.agr.nagoya-u.ac.jp/~shinkan/LIA32/index-e.html</ext-link>. Accessed: 2014 Aug 27.</mixed-citation></ref><ref id="pone.0111924-Cescatti1"><label>21</label><mixed-citation publication-type="journal">
<name><surname>Cescatti</surname><given-names>A</given-names></name> (<year>2007</year>) <article-title>Indirect estimates of canopy gap fraction based on the linear conversion of hemispherical photographs</article-title>. <source>Agric For Meteorol</source>
<volume>143</volume>:<fpage>1</fpage>&#x02013;<lpage>12</lpage>
<pub-id pub-id-type="doi">10.1016/j.agrformet.2006.04.009</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Nobis1"><label>22</label><mixed-citation publication-type="journal">
<name><surname>Nobis</surname><given-names>M</given-names></name>, <name><surname>Hunziker</surname><given-names>U</given-names></name> (<year>2005</year>) <article-title>Automatic thresholding for hemispherical canopy-photographs based on edge detection</article-title>. <source>Agric For Meteorol</source>
<volume>128</volume>:<fpage>243</fpage>&#x02013;<lpage>250</lpage>
<pub-id pub-id-type="doi">10.1016/j.agrformet.2004.10.002</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Englund1"><label>23</label><mixed-citation publication-type="journal">
<name><surname>Englund</surname><given-names>SR</given-names></name>, <name><surname>O&#x02032;Brien</surname><given-names>JJ</given-names></name>, <name><surname>Clark</surname><given-names>DB</given-names></name> (<year>2000</year>) <article-title>Evaluation of digital and film hemispherical photography and spherical densiometry for measuring forest light environments</article-title>. <source>Can J For Res</source>
<volume>30</volume>:<fpage>1999</fpage>&#x02013;<lpage>2005</lpage>
<pub-id pub-id-type="doi">10.1139/cjfr-30-12-1999</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Ishida1"><label>24</label><mixed-citation publication-type="journal">
<name><surname>Ishida</surname><given-names>M</given-names></name> (<year>2004</year>) <article-title>Automatic thresholding for digital hemispherical photography</article-title>. <source>Can J For Res</source>
<volume>34</volume>:<fpage>2208</fpage>&#x02013;<lpage>2216</lpage>
<pub-id pub-id-type="doi">10.1139/x04-103</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Kato1"><label>25</label><mixed-citation publication-type="journal">
<name><surname>Kato</surname><given-names>S</given-names></name>, <name><surname>Komiyama</surname><given-names>A</given-names></name> (<year>2000</year>) <article-title>A calibration method for adjusting hemispherical photographs to appropriate black-and-white images</article-title>. <source>J For Res</source>
<volume>5</volume>:<fpage>109</fpage>&#x02013;<lpage>111</lpage>
<pub-id pub-id-type="doi">10.1007/BF02762529</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Ryu1"><label>26</label><mixed-citation publication-type="journal">
<name><surname>Ryu</surname><given-names>Y</given-names></name>, <name><surname>Nilson</surname><given-names>T</given-names></name>, <name><surname>Kobayashi</surname><given-names>H</given-names></name>, <name><surname>Sonnentag</surname><given-names>O</given-names></name>, <name><surname>Law</surname><given-names>BE</given-names></name>, <etal>et al</etal> (<year>2010</year>) <article-title>On the correct estimation of effective leaf area index: Does it reveal information on clumping effects?</article-title>
<source>Agric For Meteorol</source>
<volume>150</volume>:<fpage>463</fpage>&#x02013;<lpage>472</lpage>
<pub-id pub-id-type="doi">10.1016/j.agrformet.2010.01.009</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Congalton1"><label>27</label><mixed-citation publication-type="book">Congalton RG, Green K (2009) Assessing the accuracy of remotely sensed data: principles and practices. 2nd ed. Boca Raton: CRC Press/Taylor &#x00026; Francis. 183 p.</mixed-citation></ref><ref id="pone.0111924-BarneySmith1"><label>28</label><mixed-citation publication-type="other">Barney Smith EH (2010) An analysis of binarization ground truthing ACM Press. pp.27&#x02013;34. Available: <ext-link ext-link-type="uri" xlink:href="http://portal.acm.org/citation.cfm?doid=1815330.1815334">http://portal.acm.org/citation.cfm?doid=1815330.1815334</ext-link>. Accessed: 2014 Oct 29.</mixed-citation></ref><ref id="pone.0111924-Ntirogiannis1"><label>29</label><mixed-citation publication-type="other">Ntirogiannis K, Gatos B, Pratikakis I (2008) An objective evaluation methodology for document image binarization techniques IEEE. pp.217&#x02013;224. Available: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4669964&#x00026;tag=1">http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4669964&#x00026;tag=1</ext-link>. Accessed: 2014 Oct 29.</mixed-citation></ref><ref id="pone.0111924-GonzlezTagle1"><label>30</label><mixed-citation publication-type="journal">
<name><surname>Gonz&#x000e1;lez Tagle</surname><given-names>MA</given-names></name>, <name><surname>Jim&#x000e9;nez P&#x000e9;rez</surname><given-names>J</given-names></name>, <name><surname>Himmelsbach</surname><given-names>W</given-names></name> (<year>2011</year>) <article-title>Impact of firewood extraction on leaf area index and canopy openness in mixed pine-oak forests in northeast Mexico</article-title>. <source>Forstarchiv</source>
<volume>82</volume>:<fpage>20</fpage>&#x02013;<lpage>25</lpage>.</mixed-citation></ref><ref id="pone.0111924-Beaudet1"><label>31</label><mixed-citation publication-type="journal">
<name><surname>Beaudet</surname><given-names>M</given-names></name>, <name><surname>Messier</surname><given-names>C</given-names></name> (<year>2002</year>) <article-title>Variation in canopy openness and light transmission following selection cutting in northern hardwood stands: an assessment based on hemispherical photographs</article-title>. <source>Agric For Meteorol</source>
<volume>110</volume>:<fpage>217</fpage>&#x02013;<lpage>228</lpage>
<pub-id pub-id-type="doi">10.1016/S0168-1923(01)00289-1</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Rich1"><label>32</label><mixed-citation publication-type="book">Rich P (1989) A manual for analysis of hemispherical canopy photography. New Mexico, USA: Los Alamos National Lab. 92 p.</mixed-citation></ref><ref id="pone.0111924-Weiss1"><label>33</label><mixed-citation publication-type="journal">
<name><surname>Weiss</surname><given-names>M</given-names></name>, <name><surname>Baret</surname><given-names>F</given-names></name>, <name><surname>Smith</surname><given-names>GJ</given-names></name>, <name><surname>Jonckheere</surname><given-names>I</given-names></name>, <name><surname>Coppin</surname><given-names>P</given-names></name> (<year>2004</year>) <article-title>Review of methods for in situ leaf area index (LAI) determination</article-title>. <source>Agric For Meteorol</source>
<volume>121</volume>:<fpage>37</fpage>&#x02013;<lpage>53</lpage>
<pub-id pub-id-type="doi">10.1016/j.agrformet.2003.08.001</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Rasband1"><label>34</label><mixed-citation publication-type="other">Rasband WS (2014) ImageJ. Bethesda, Maryland, US: U. S. National Institutes of Healt. Available: <ext-link ext-link-type="uri" xlink:href="http://imagej.nih.gov/ij/">http://imagej.nih.gov/ij/</ext-link>. Accessed: 2013 Feb 13.</mixed-citation></ref><ref id="pone.0111924-Nobis2"><label>35</label><mixed-citation publication-type="other">Nobis M (2005) SideLook 1.1 - Imaging software for the analysis of vegetation structure with true-colour photographs. Available: <ext-link ext-link-type="uri" xlink:href="http://www.appleco.ch">http://www.appleco.ch</ext-link>. Accessed: 2013 Apr 15.</mixed-citation></ref><ref id="pone.0111924-Prewitt1"><label>36</label><mixed-citation publication-type="journal">
<name><surname>Prewitt</surname><given-names>J</given-names></name>, <name><surname>Mendelsohn</surname><given-names>ML</given-names></name> (<year>1966</year>) <article-title>The analysis of cell images</article-title>. <source>Ann N Y Acad Sci</source>
<volume>128</volume>:<fpage>1035</fpage>&#x02013;<lpage>1053</lpage>.<pub-id pub-id-type="pmid">5220765</pub-id></mixed-citation></ref><ref id="pone.0111924-Cohen1"><label>37</label><mixed-citation publication-type="journal">
<name><surname>Cohen</surname><given-names>J</given-names></name> (<year>1960</year>) <article-title>A coefficient of agreement for nominal scales</article-title>. <source>Educ Psychol Meas</source>
<volume>20</volume>:<fpage>37</fpage>&#x02013;<lpage>46</lpage>
<pub-id pub-id-type="doi">10.1177/001316446002000104</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Comber1"><label>38</label><mixed-citation publication-type="journal">
<name><surname>Comber</surname><given-names>A</given-names></name>, <name><surname>Fisher</surname><given-names>P</given-names></name>, <name><surname>Wadsworth</surname><given-names>R</given-names></name> (<year>2005</year>) <article-title>Comparing the consistency of expert land cover knowledge</article-title>. <source>Int J Appl Earth Obs Geoinformation</source>
<volume>7</volume>:<fpage>189</fpage>&#x02013;<lpage>201</lpage>
<pub-id pub-id-type="doi">10.1016/j.jag.2005.02.001</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Wagner3"><label>39</label><mixed-citation publication-type="other">Wagner S (1994) Estimation of radiation in Forests through hemispherical pictures - Methodology and application. PhD thesis Forschungszentrum Wald&#x000f6;kosysteme der Universit&#x000e4;t G&#x000f6;ttingen (Germany).</mixed-citation></ref><ref id="pone.0111924-Jonckheere2"><label>40</label><mixed-citation publication-type="journal">
<name><surname>Jonckheere</surname><given-names>I</given-names></name>, <name><surname>Fleck</surname><given-names>S</given-names></name>, <name><surname>Nackaerts</surname><given-names>K</given-names></name>, <name><surname>Muys</surname><given-names>B</given-names></name>, <name><surname>Coppin</surname><given-names>P</given-names></name>, <etal>et al</etal> (<year>2004</year>) <article-title>Review of methods for in situ leaf area index determination</article-title>. <source>Agric For Meteorol</source>
<volume>121</volume>:<fpage>19</fpage>&#x02013;<lpage>35</lpage>
<pub-id pub-id-type="doi">10.1016/j.agrformet.2003.08.027</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Frazer2"><label>41</label><mixed-citation publication-type="book">Frazer GW, Lertzman KP, Trofymow JA (1997)A method for estimating canopy openness, effective leaf area index, and photosynthetically active photon flux density using hemispherical photography and computerized image analysis techniques. Victoria, B.C.: Pacific Forestry Centre. 81 p.</mixed-citation></ref><ref id="pone.0111924-VanGardingen1"><label>42</label><mixed-citation publication-type="journal">
<name><surname>Van Gardingen</surname><given-names>P</given-names></name>, <name><surname>Jackson</surname><given-names>G</given-names></name>, <name><surname>Hernandez-Daumas</surname><given-names>S</given-names></name>, <name><surname>Russell</surname><given-names>G</given-names></name>, <name><surname>Sharp</surname><given-names>L</given-names></name> (<year>1999</year>) <article-title>Leaf area index estimates obtained for clumped canopies using hemispherical photography</article-title>. <source>Agric For Meteorol</source>
<volume>94</volume>:<fpage>243</fpage>&#x02013;<lpage>257</lpage>
<pub-id pub-id-type="doi">10.1016/S0168-1923(99)00018-0</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Oke1"><label>43</label><mixed-citation publication-type="book">Oke TR (1987) Boundary layer climates. Psychology Press. 460 p.</mixed-citation></ref><ref id="pone.0111924-Park1"><label>44</label><mixed-citation publication-type="journal">
<name><surname>Park</surname><given-names>E</given-names></name>, <name><surname>Cho</surname><given-names>M</given-names></name>, <name><surname>Ki</surname><given-names>C-S</given-names></name> (<year>2009</year>) <article-title>Correct use of repeated measures analysis of variance</article-title>. <source>Korean J Lab Med</source>
<volume>29</volume>:<fpage>1</fpage>
<pub-id pub-id-type="doi">10.3343/kjlm.2009.29.1.1</pub-id>
<pub-id pub-id-type="pmid">19262072</pub-id></mixed-citation></ref><ref id="pone.0111924-R1"><label>45</label><mixed-citation publication-type="other">R Core Team (2013) R: a language and environment for statistical computing. Vienna, Austria: R Foundation for Statistical Computing. Available: <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org/">http://www.R-project.org/</ext-link>. Accessed: 2013 Mar 5.</mixed-citation></ref><ref id="pone.0111924-Olsson1"><label>46</label><mixed-citation publication-type="journal">
<name><surname>Olsson</surname><given-names>L</given-names></name>, <name><surname>Carlsson</surname><given-names>K</given-names></name>, <name><surname>Grip</surname><given-names>H</given-names></name>, <name><surname>Perttu</surname><given-names>K</given-names></name> (<year>1982</year>) <article-title>Evaluation of forest-canopy photographs with diode-array scanner OSIRIS</article-title>. <source>Can J For Res</source>
<volume>12</volume>:<fpage>822</fpage>&#x02013;<lpage>828</lpage>
<pub-id pub-id-type="doi">10.1139/x82-123</pub-id>
</mixed-citation></ref><ref id="pone.0111924-Inoue2"><label>47</label><mixed-citation publication-type="journal">
<name><surname>Inoue</surname><given-names>A</given-names></name>, <name><surname>Yamamoto</surname><given-names>K</given-names></name>, <name><surname>Mizoue</surname><given-names>N</given-names></name>, <name><surname>Kawahara</surname><given-names>Y</given-names></name> (<year>2004</year>) <article-title>Effects of image quality, size and camera type on forest light environment estimates using digital hemispherical photography</article-title>. <source>Agric For Meteorol</source>
<volume>126</volume>:<fpage>89</fpage>&#x02013;<lpage>97</lpage>
<pub-id pub-id-type="doi">10.1016/j.agrformet.2004.06.002</pub-id>
</mixed-citation></ref></ref-list></back></article>
